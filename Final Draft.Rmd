---
title: "Forecasting Climate-related Search Terms in Google Web Search"
subtitle: "Repository: https://github.com/cynthiazyii/ChenjiaCynthiaWill_TSA_project"
author: "Zhenghao Lin, Chenjia Liu, Cynthia Zhou"
date: "2024-04-23"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction, Motivations, Relevance, Objectives
Climate change has become one of the most pressing issues facing humanity in the 21st century. With the escalating impacts of global warming, extreme weather events, and environmental degradation becoming more visible, public awareness and concern have surged. In this digital age, the internet has become a primary avenue for education and engagement on environmental issues. As the world's predominant search engine, Google offers invaluable insights into global interest in climate topics, making it a valuable resource for public concern evaluation.

This report utilizes Google Trends data to perform a comprehensive time series analysis of the search volume for "Climate" to identify underlying patterns, trends, and anomalies in public interest over time. Using advanced statistical tools and methods, this analysis will:
1. Forecast Future Trends: Apply various models to the original dataset to predict future changes in public interest concerning climate issues.
2. Assess the Impact of Outliers: Compare forecasts from the original data with those from a modified dataset that excludes outliers, evaluating how these anomalies affect overall predictions.
3. Analyze Spatial Variations: Conduct a spatial analysis of relative search volumes to map regional differences in interest regarding climate-related topics across the globe.

Through these analyses, the report seeks to provide a comprehensive overview of the public's engagement with climate issues, offering insights that could inform policymakers, educators, and environmental organizations in their efforts to foster greater awareness and action.

# Data Information
Our data set is sourced from Google Trends. As the original data is interest index which only represents the popularity of total search term in certain time periods or regions, we use a Chrome extension called Glimpse-Google Trend Supercharged to convert interest index into absolute values. We captured the number of searches for climate-related search terms globally from 2004 to the present.

```{r data, echo=FALSE}
datainfor <- data.frame( Data = c("Source: ", "Search Term: ", "Time Range: ", "Spatial Range: "), 
                         Information = c("Google Trend", "Climate","2004 to present","Global")
                        )
knitr::kable(datainfor, caption = "Data Information")
```

```{r include=FALSE}
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(cowplot)
library(GGally)
library(readxl)
library(wbstats) 
library(purrr)
library(sf)
library('rnaturalearth')
library(sp)
library(gridExtra)
```

# Methodology

The models that are being used by this analysis include TBATS (Trigonometric seasonality, Box-Cox transformation, ARMA errors, Trend and Seasonal components) model, ARIMA + FOURIER terms, STL+ETS (Seasonal and Trend decomposition using Loess + Error, Trend, Seasonal) model, Neural Network, and SSES (State Space Exponential Smoothing) model. A short description of the models are given below:

### 1 TBATS
TBATS was designed to forecast time series with multiple seasonal periods. For example, daily data may have a weekly pattern as well as an annual pattern. Or hourly data can have three seasonal periods: a daily pattern, a weekly pattern, and an annual pattern. In TBATS, a Box-Cox transformation is applied to the original time series, and then this is modelled as a linear combination of an exponentially smoothed trend, a seasonal component and an ARMA component. The seasonal components are modelled by trigonometric functions via Fourier series. TBATS conducts some hyper-parameter tuning (e.g. which of these components to keep and which to discard) using AIC.

### 2 ARIMA + FOURIER terms
The ARIMA model with Fourier terms for seasonal adjustment is a sophisticated approach for forecasting time series data, particularly when the data exhibits complex seasonality that cannot be adequately modeled by simple seasonal ARIMA (SARIMA) components alone.

### 3 STL+ETS
STL is a versatile and robust method for decomposing time series. STL is an acronym for “Seasonal and Trend decomposition using Loess”, while loess is a method for estimating nonlinear relationships. The ETS models are a family of time series models with an underlying state space model consisting of a level component, a trend component (T), a seasonal component (S), and an error term (E).

### 4 Neural Network
Neural networks or simulated neural networks are a subset of machine learning which is inspired by the human brain. They mimic how biological neurons communicate with one another to come up with a decision. A neural network consists of an input layer, a hidden layer, and an output layer. The first layer receives raw input, it is processed by multiple hidden layers, and the last layer produces the result. 

### 5 SSES
The exponential smoothing state space model is a statistical model that generates prediction intervals and point forecasts. It is a stochastic data generating process that can produce an entire forecast distribution. The exponential smoothing methods generate point forecasts, and the statistical models generate the same point forecasts, but can also generate prediction intervals.


# Analysis
## Forcast of original data

```{r include=FALSE}
raw_df<-read.csv("./Data/climate-timeline_Glimpse_Google-Trends.csv", skip = 5) 

df <- raw_df %>%
  mutate(Time = as.Date(Time, format="%Y-%m-%d")) %>% 
  rename(Date = Time,
         Normalized_Value = `Normalized.Value..0.100.`,
         Absolute_Volume = `Absolute.Google.Search.Volume`)
```

```{r echo=FALSE}
ts_df <- msts(df$Absolute_Volume, 
                           seasonal.periods =c(3,12),
                           start=c(2003,12))

ts_df_training <- subset(ts_df,end = length(ts_df)-12)
                         
ts_df_testing <- subset(ts_df,start = length(ts_df)-12)

ts_df_training %>% mstl() %>%
  autoplot()
```
First, the data set was read and the Time is converted to "date". The variable of interest (absolute search volume) was renamed and converted to a time series object. A training set and test set was then obtained by filtering data. The last 12 observation was selected as holdouts. The time series data set was plotted to check for trends and seasonality. The seasonal period is set using 3 (quarterly) and 12 (manually).

```{r echo=FALSE, warning=FALSE,fig.width=6, fig.height=3}
plot_grid(
  autoplot(Acf(df$Absolute_Volume, lag = 40, plot=FALSE), 
                main = "ACF Absolute Search Volume"),
  autoplot(Pacf(df$Absolute_Volume, lag = 40, plot=FALSE),  
                  main = "PACF Absolute Search Volume")
)

```

The ACF plot displays the correlation between the time series data and its lagged values over different time lags. The plot shows several spikes that are outside the blue dashed confidence interval lines, especially at the initial lags. This suggests that there is a significant autocorrelation at those lags. The PACF plot, on the other hand, shows the partial correlation between the time series and its lagged values, controlling for the values at shorter lags. The significant spike at the first lag indicates a strong correlation. Since the spike at lag 1 is followed by a cutoff, it might suggest an AR(1) component.The slow decay in the ACF plot could indicate that the data is non-stationary or has seasonal patterns.

```{r echo=FALSE}
#TBATS
TBATS_fit <- tbats(ts_df_training)

TBATS_for <- forecast(TBATS_fit, h=12)

p11<-autoplot(ts_df_testing) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ggtitle("TBATS Forecasted Search Volume")

TBATS_scores <- accuracy(TBATS_for$mean,ts_df_testing)
```

```{r echo=FALSE}
#ARIMA
ARIMA_fit <- auto.arima(ts_df_training, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_df_training, 
                                          K=c(1,2))
                             )


ARIMA_for <- forecast(ARIMA_fit,
                           xreg=fourier(ts_df_training,
                                        K=c(1,2),
                                        h=12),
                           h=12
                           )


p12<-autoplot(ts_df_testing) +
  autolayer(ARIMA_for, series="ARIMA",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("ARIMA Forecasted Search Volume")

ARIMA_scores <- accuracy(ARIMA_for$mean,ts_df_testing)
```

```{r echo=FALSE,warning=FALSE}
#STL+ETS
ETS_fit <-  stlf(ts_df_training,h=12)

p13<-autoplot(ts_df_testing) +
  autolayer(ETS_fit$mean, series="ETS",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("ETS Forecasted Search Volume")

ETS_scores <- accuracy(ETS_fit$mean,ts_df_testing)
```

```{r echo=FALSE}
#NN
NN_fit <- nnetar(ts_df_training,p=0,P=1,xreg=fourier(ts_df_training, K=c(1,4)))

NN_for <- forecast(NN_fit, h=12,xreg=fourier(ts_df_training, 
                                          K=c(1,4),h=12))

#Plot model + observed data
p14<-autoplot(ts_df_testing) +
  autolayer(NN_for, series="NN",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("NN Forecasted Search Volume")

NN_scores <- accuracy(NN_for$mean,ts_df_testing)
```

```{r echo=FALSE}
#SSES
SSES_seas <- es(ts_df_training,model="AMM",h=12,holdout=FALSE)

p15<-autoplot(ts_df_testing) +
  autolayer(SSES_seas$forecast, series="SSES")+
  ylab("Search Volume")+
  ggtitle("SSES Forecasted Search Volume")

SSES_scores <- accuracy(SSES_seas$forecast,ts_df_testing)

grid.arrange(p11, p12, p13, p14, p15, nrow = 3)
```

```{r include=FALSE}
# SCORE
scores <- as.data.frame(
  rbind(ETS_scores, ARIMA_scores, TBATS_scores, NN_scores, SSES_scores)
  )
row.names(scores) <- c("STL+ETS", "ARIMA+Fourier","TBATS","NN","SSES")

#choose model with lowest RMSE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))
```

```{r echo=FALSE}
#SCORE TABLE
kbl(scores, 
      caption = "Forecast Accuracy for Daily Active Power",
      digits = array(5,ncol(scores))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(scores[,"RMSE"]))
```

The data was trained from December 2003 to March 2023 and tested from April 2023 to March 2024. Predictions were made for the next 12 months. Based on the residual scores, the neural network (NN) model outperformed others, achieving the lowest RMSE of 353,492.8. In contrast, the STL+ETS model registered the highest RMSE at 1,339,766.2. Consequently, the NN model was selected for predicting the absolute search volume. It's important to note that the residual scores were quite high. This high error rate is partly because our base numbers are substantial, typically in the millions. The NN's residual score, although in the hundreds of thousands, represents about 10 percent of the data, which is still considered a significant error. Moving forward, the next step involves removing outliers, which are causing huge spikes, and rerunning the candidate model.

```{r echo=FALSE}
#FORECAST
NN_fit_2 <- nnetar(ts_df,p=0,P=1,xreg=fourier(ts_df, K=c(1,4)))

NN_for_2 <- forecast(NN_fit_2, h=12,xreg=fourier(ts_df, 
                                          K=c(1,4),h=12))

#Plot FORECAST
autoplot(NN_for_2)+
  ylab("Search Volume") 


```

## Outlier Removal and Model Optimization
This section of the report builds upon the initial time series analysis by addressing outliers in the dataset and re-evaluating the forecasting models to identify the best performer in a refined dataset. The focus is to enhance model accuracy by minimizing the distortion effects caused by outliers.

### Outlier Detection and Interpolation
The process began by identifying outliers using the Interquartile Range (IQR) method, a robust technique that determines extreme values based on the distribution's quartiles. Outliers were defined as observations that fall below the first quartile minus 1.5 times the IQR or above the third quartile plus 1.5 times the IQR. These outliers were then replaced using spline interpolation, which provides a smooth estimate that is less likely to be influenced by extreme values, hence maintaining the integrity of the time series.

### Methodology
The outliers in the Absolute_Volume data were first visually identified and marked in the dataset. Below is the graph of the time series plot with outliers identified through IQR method.

```{r echo=FALSE, warning=FALSE, fig.width=6, fig.height=3}
#Identify the outliers
IQR_value <- IQR(df$Absolute_Volume, na.rm = TRUE)
upper_bound <- quantile(df$Absolute_Volume, 0.75, na.rm = TRUE) + 1.5 * IQR_value
lower_bound <- quantile(df$Absolute_Volume, 0.25, na.rm = TRUE) - 1.5 * IQR_value

# Add a new column for outliers
df$Outlier <- ifelse(df$Absolute_Volume > upper_bound | df$Absolute_Volume < lower_bound, "Yes", "No")

ggplot(df, aes(x = Date, y = Absolute_Volume)) + 
  geom_line(color = "blue", size = 1) + 
  geom_point(aes(color = Outlier), size = 2) +  # Points colored based on outlier status
  scale_color_manual(values = c('No' = "blue", 'Yes' = "red")) +  # Red for outliers
  labs(title = "Time Series Residuals with Outliers Highlighted",
       x = "Date",
       y = "Absolute_Volume")
```

The na.spline function from the zoo package was then used to interpolate and fill in these outliers based on neighboring values, which helps in preserving the trend and seasonal patterns of the series. The following figure from the analysis illustrates the original data against the interpolated data, showing how the outliers have been integrated.


```{r echo=FALSE,fig.width=6, fig.height=3}
df$Interpolated_Volume <- df$Absolute_Volume

outliers_indices <- which(df$Outlier == "Yes")
df$Interpolated_Volume[outliers_indices] <- NA

df$Interpolated_Volume <- na.spline(df$Interpolated_Volume)

ggplot(df, aes(x = Date)) + 
  geom_line(aes(y = Absolute_Volume, colour = "Original"), size=1, alpha=0.5) +
  geom_line(aes(y = Interpolated_Volume, colour = "Interpolated"), size=1) +
  scale_colour_manual("", 
                      breaks = c("Original", "Interpolated"),
                      values = c("grey", "blue")) +
  labs(title = "Original vs Interpolated Time Series",
       x = "Date",
       y = "Volume")

```

### Model Re-evaluation
With the outliers addressed, the dataset was split into training and testing sets. The analysis method and forecasting models used in the previous section were re-applied to this cleaned data.
```{r echo=FALSE}
clean_df <- df %>%
  select(Date, Interpolated_Volume)

ts_clean_df <- msts(df$Interpolated_Volume, 
                           seasonal.periods =c(3,12),
                           start=c(2003,12))

ts_clean_df_training <- subset(ts_clean_df,end = length(ts_clean_df)-12)
                         
ts_clean_df_testing <- subset(ts_clean_df,start = length(ts_clean_df)-12)

ts_clean_df_training %>% mstl() %>%
  autoplot()
```
When looking at the ACF and PACF plots of the cleaned data frame, the ACF plot reveals strong positive autocorrelations at the initial lags and then gradually decline as the lags increase, indicating potential non-stationarity within the time series data. Furthermore, the ACF plot exhibits a potential seasonal pattern through its recurring spikes at specific lags.
For the PACF plot, since it has a significant spike at the first lag and then cut off after it, the plot suggests at least an AR(1) model. This result align with the observation with the ACF and PACF plots of the original dataset.

```{r echo=FALSE, warning=FALSE,fig.width=6, fig.height=3}
plot_grid(
  autoplot(Acf(clean_df$Interpolated_Volume, lag = 40, plot=FALSE), 
                main = "ACF Absolute Search Volume"),
  autoplot(Pacf(clean_df$Interpolated_Volume, lag = 40, plot=FALSE),  
                  main = "PACF Absolute Search Volume")
)
```

```{r echo=FALSE}
#TBATS
TBATS_fit_clean <- tbats(ts_clean_df_training)

TBATS_for_clean <- forecast(TBATS_fit_clean, h=12)

p21<-autoplot(ts_clean_df_testing) +
  autolayer(TBATS_for_clean, series="TBATS",PI=FALSE)+
  ggtitle("TBATS Forecasted Search Volume")

TBATS_scores_clean <- accuracy(TBATS_for_clean$mean,ts_clean_df_testing)
```

```{r echo=FALSE}
#ARIMA
ARIMA_fit_clean <- auto.arima(ts_clean_df_training, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_clean_df_training, 
                                          K=c(1,2))
                             )


ARIMA_for_clean <- forecast(ARIMA_fit_clean,
                           xreg=fourier(ts_clean_df_training,
                                        K=c(1,2),
                                        h=12),
                           h=12
                           )

p22<-autoplot(ts_clean_df_testing) +
  autolayer(ARIMA_for_clean, series="ARIMA",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("ARIMA Forecasted Search Volume")

ARIMA_scores_clean <- accuracy(ARIMA_for_clean$mean,ts_clean_df_testing)
```

```{r echo=FALSE, warning=FALSE}
#STL+ETS
ETS_fit_clean <-  stlf(ts_clean_df_training,h=12)

p23<-autoplot(ts_clean_df_testing) +
  autolayer(ETS_fit_clean$mean, series="ETS",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("ETS Forecasted Search Volume")

ETS_scores_clean <- accuracy(ETS_fit_clean$mean,ts_clean_df_testing)
```

```{r echo=FALSE}
#NN
NN_fit_clean <- nnetar(ts_clean_df_training,p=0,P=1,xreg=fourier(ts_clean_df_training, K=c(1,4)))

NN_for_clean <- forecast(NN_fit_clean, h=12,xreg=fourier(ts_clean_df_training, 
                                          K=c(1,4),h=12))

#Plot model + observed data
p24<-autoplot(ts_clean_df_testing) +
  autolayer(NN_for_clean, series="NN",PI=FALSE)+
  ylab("Search Volume")+
  ggtitle("NN Forecasted Search Volume")

NN_scores_clean <- accuracy(NN_for_clean$mean,ts_clean_df_testing)
```

```{r echo=FALSE}
#SSES
SSES_seas_clean <- es(ts_clean_df_training,model="AMM",h=12,holdout=FALSE)

p25<-autoplot(ts_clean_df_testing) +
  autolayer(SSES_seas_clean$forecast, series="SSES")+
  ylab("Search Volume")+
  ggtitle("SSES Forecasted Search Volume")

SSES_scores_clean <- accuracy(SSES_seas_clean$forecast,ts_clean_df_testing)
grid.arrange(p21, p22, p23, p24, p25, nrow = 3)
```

```{r include=FALSE}
# SCORE for clean_df
scores_clean <- as.data.frame(
  rbind(ETS_scores_clean, ARIMA_scores_clean, TBATS_scores_clean, NN_scores_clean, SSES_scores_clean)
  )
row.names(scores_clean) <- c("STL+ETS", "ARIMA+Fourier","TBATS","NN","SSES")
```

### Results
Below is the model score table of cleaned dataset with outliers removed. Compared to the original data frame, the cleaning process significantly improved model performance. The TBATS model emerged as the best model with the lowest RMSE, indicating the highest forecasting accuracy among the evaluated models on the cleaned dataset. The improvement underscores the impact of outliers removal on enhancing model reliability and accuracy.

```{r echo=FALSE}
#SCORE TABLE
kbl(scores_clean, 
      caption = "Forecast Accuracy for Daily Active Power with Cleaned Dataset",
      digits = array(5,ncol(scores_clean))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(scores_clean[,"RMSE"]))
```

Below is the forecast of the search volume of term "Climate" on google for next 12 months with TBATS forecasting model using cleaned dataset with outliers removded.

```{r echo=FALSE}
#FORECAST for clean_df
TBATS_fit_clean_2 <- tbats(ts_clean_df)

TBATS_for_clean_2 <- forecast(TBATS_fit_clean_2, h=12)

autoplot(TBATS_for_clean_2) +
  ylab("Search Volume") 

```

## Spatial Characteristics
In the global distribution map of climate-related topic web search, African countries enjoy the most popularity as a fraction of total searches in their region. Related search terms account for a moderate proportion in North America, Australia and South Asia, while it was not that popular in South America, Europe and other Asia regions. On a country level, Ethiopia and Zimbabwe had the largest proportion of climate search terms in their total searches.

Population can be a possible reason for the difference. In African countries, where few people have access to the Internet, the proportion of climate search terms may be magnified. In addition, international organizations and non-governmental organizations such as the United Nations Environment Program are headquartered in Africa, leading to related behaviors. The extent to which different countries are affected by climate change is also important. Countries like the Philippines, which are at the forefront of climate change, rank very high both in the interest index and in absolute values. People who live there are naturally more concerned about the climate.

```{r include=FALSE}
spatial <- read_excel("Data/spatial.xlsx")
```

```{r echo=FALSE}
world_map <- ne_countries(scale = "medium", returnclass = "sf")
merged_data <- left_join(world_map, spatial, by = c("name" = "Country"))
merged_data$Index <- as.numeric(as.character(merged_data$Index))
ggplot(data = merged_data) +
  geom_sf(aes(fill = Index)) +
  scale_fill_gradient(low = "#E6F2FD", high = 4, na.value = "lightgrey") +
  labs(title = "Global Climate Web Sesearch Map",
       fill = "Search Interest Index")

```

# Limiations
Our dataset inherently possesses several limitations that could skew our findings' accuracy. Initially, we utilized both the absolute and relative search volumes of the term "Climate". However, the ambiguity of this term means it is often searched in contexts unrelated to climate change, such as weather conditions or trends in various fields. This broad usage can lead to an overestimation of both absolute and relative search volumes. Additionally, while Google remains the most popular search engine globally, it is not the only one with significant market presence. For example, Baidu holds a substantial share of the market, particularly in China—the country with the second largest population. By not incorporating data from Baidu, particularly given its dominance in Chinese searches, our research may overlook a critical segment of global search trends, potentially resulting in biased outcomes.

Within the data obtained from Google, several issues still persist. Our analysis from first section highlighted the presence of outliers—abnormal spikes in the data which could distort our forecasts. To mitigate potential biases from these anomalies, we removed these outliers to try to achieve more reliable outcomes. Although this method generally improved model performance, it raised some new concerns, especially the risk of overfitting. By employing sophisticated techniques to detect and eliminate outliers, we unavoidably increased the likelihood that our models might become overly fitted to our current dataset. Such overfitting could undermine the accuracy of future predictions by making our models less capable of generalizing from new data. Moreover, our current dataset may not be extensive enough to conclusively differentiate between genuine seasonal effects and anomalies. Some of the spikes might not represent underlying seasonal trends but could instead be one-time events or products of irregular fluctuations. These non-recurring spikes could potentially skew the forecasts.

Another notable issue is the underrepresentation of certain countries in our study. The spatial analysis section excludes countries with low search volumes, many of which are also experiencing significant impacts from climate change. This omission could further contribute to an incomplete global perspective in our research.

# Next Steps
In the future, if resources and time allowed, we will take following steps to further our investigation. 

Firstly, we need to expand our data sources. To address the issue of over-reliance on Google and the consequent geographic and demographic biases, we should integrate data from other significant search engines, such as Baidu. By broadening our dataset to include multiple search engines, we can achieve a more balanced and globally representative analysis. This expansion will help us better understand regional differences in search behaviors and refine our interpretations of global interest in climate-related topics.

Secondly, improving data filtering techniques to better differentiate between searches related to climate change and those triggered by unrelated factors is essential. We hope that Google can develop more sophisticated algorithms that can contextually analyze search terms and distinguish between searches for climate change information and other uses of the word "climate." This might involve natural language processing (NLP) techniques or machine learning models trained.

Additionally, addressing the problem of data outliers and overfitting requires a revision of our current methodologies. We should implement more robust statistical methods to handle outliers without removing them entirely, thus preserving valuable data that might be relevant for understanding extreme but significant phenomena. 

Lastly, we must strive to include underrepresented regions in our analysis. It’s important to develop strategies to estimate search volumes in countries with lower internet penetration or those typically excluded from digital data analyses. This might involve proxy measures or collaborations with local data providers to capture a fuller picture of the global discourse around climate change.

# Conclusion
This report analyzes the search volume trends of the term "Climate" using Google Trends data to gain insights into public interest over time. Our methodology involved a comprehensive time series analysis on both original dataset and the adjusted data frame with outliers removed, and an assessment comparison of search behaviors globally.

The results of our analysis indicate a steady increase in the future search volume for "Climate." This upward trend suggests a growing public awareness and interest in climate-related issues. By successfully removing outliers and refining the data, the predictive models, particularly the TBATS model, provided robust forecasts that reinforce our understanding of this increasing engagement. This increase in search volume can be interpreted as a positive sign that climate change is becoming a more significant concern for people worldwide, potentially signaling greater support for policies and initiatives aimed at combating climate change. As we move forward, it will be important to continue monitoring these trends and expand our data collection efforts to include a wider array of search engines and regions to further validate and refine our forecasts. By doing so, we can ensure that our models remain adaptable and accurate, providing valuable insights to policymakers, educators, and environmental organizations aiming to foster an informed and engaged public.


